%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{xurl}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}
%\usepackage[font=small]{caption}

\renewcommand{\arraystretch}{1.3}

\usepackage{xr}
\externaldocument{paper-misspec-supp}

\linenumbers
\doublespacing
%\onehalfspacing
%\usepackage[authoryear]{natbib}
\usepackage[numbers,super]{natbib} %\bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm}
\usepackage{algpseudocode}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}


\title{Identifying and correcting for misspecifications\\in GWAS summary statistics and polygenic scores}
\author{Florian Priv\'e,$^{\text{1,}*}$ Julyan Arbel,$^{\text{2}}$ Hugues Aschard,$^{\text{3,4}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,5}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-Based Research, Aarhus University, Aarhus, 8210, Denmark. \\
\noindent$^{\text{\sf 2}}$Univ.\ Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, 38000, France. \\
\noindent$^{\text{\sf 3}}$Department of Computational Biology, Institut Pasteur, Paris, 75015, France. \\
\noindent$^{\text{\sf 4}}$Program in Genetic Epidemiology and Statistical Genetics, Harvard T.H. Chan School of Public Health, Boston, MA, 02115, USA. \\
\noindent$^{\text{\sf 5}}$Bioinformatics Research Centre, Aarhus University, Aarhus, 8000, Denmark. \\
\noindent$^\ast$To whom correspondence should be addressed.\\

\noindent Contact: \url{florian.prive.21@gmail.com}

%\vspace*{6em}
\clearpage

\begin{abstract}
Publicly available genome-wide association studies (GWAS) summary statistics exhibit uneven quality, which can impact the validity of follow-up analyses. First, we present an overview of possible misspecifications that come with GWAS summary statistics. Then, in both simulations and real data analyses, we show that additional information such as imputation INFO scores, allele frequencies, and per-variant sample sizes in GWAS summary statistics can be used to detect possible issues and correct for misspecifications in the GWAS summary statistics. One important motivation for us is to improve the predictive performance of polygenic scores built from these summary statistics. Unfortunately, due to the lack of reporting standards for GWAS summary statistics, this additional information is not systematically reported. We also show that using well-matched LD references can improve model fit and translate into more accurate prediction. Finally, we discuss how to make polygenic score methods such as lassosum and LDpred2 more robust to these misspecifications to improve their predictive power.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Contrary to individual-level genotypes and phenotypes, summary statistics resulting from genome-wide association studies (GWAS) are widely available, and very large sample sizes can be obtained through meta-analyses \cite[]{yengo2022saturated}.
GWAS summary statistics have been extensively used to derive polygenic scores (PGS), perform fine-mapping, and estimate a range of key genetic architecture parameters \cite[]{pasaniuc2017dissecting,prive2021finding,chen2021improved}.
However, GWAS summary statistics come with uneven imputation accuracy.
There is also heterogeneity in the information made available in these summary statistics; for example, per-variant imputation INFO scores, sample sizes and allele frequencies are often missing.
Moreover, many methods based on summary statistics use Bayesian models and iterative algorithms, which can be particularly sensitive to model misspecifications \cite[]{WALKER20131621,miller2018robust}.

We present an overview of possible misspecifications that come with GWAS summary statistics in Table \ref{tab:overview}. 
First, the total sample size used can be misestimated, which would result in a biased estimation of the SNP heritability. For example, the total effective sample size is overestimated when computed from the total number of cases and controls from a meta-analysis of binary outcomes \cite[]{grotzinger2021pervasive}; using BOLT-LMM summary statistics can result in an increased effective sample size \cite[]{loh2018mixed,gazal2018functional}; and using SAIGE on binary traits with a large prevalence can result in a reduced effective sample size \cite[]{zhou2018efficiently,mbatchou2021computationally}. 
Second, per-variant sample sizes can vary substantially and be much smaller than the total sample size when meta-analyzing GWAS summary statistics from multiple cohorts with different sets of variants \cite[]{wang2021global}.
Using very different per-variant sample sizes can be problematic for models implicitly assuming that summary statistics have all been derived from the same individuals \cite[]{zhu2017bayesian,zhou2021fast}.
Third, many genetic variants are imputed, with association statistics being reported for the allele dosages instead of the true alleles, which can lead to some bias in the summary statistics.
Fourth, the imputation quality of each variant (e.g.\ INFO scores), often used in a quality control (QC) step in statistical genetics analyses, can be severely misestimated (often overestimated) when computed from multi-ancestry individuals instead of a more homogeneous subset.
Fifth, errors such as allele inversions can be present in the summary statistics; QC is particularly important here.
Sixth, many follow-up analyses require using linkage disequilibrium (LD) from a reference panel. There can be some mismatch between the GWAS summary statistics and the LD reference used, which can e.g.\ lead to suboptimal predictive performance for polygenic scores.


\begin{table}[!htb]
	\centering
	\begin{tabular}{|p{\dimexpr0.21\textwidth-2\tabcolsep-\arrayrulewidth\relax}|
			p{\dimexpr0.49\textwidth-2\tabcolsep-\arrayrulewidth\relax}|
			p{\dimexpr0.3\textwidth-2\tabcolsep-\arrayrulewidth\relax}|}
		\hline
		\textbf{Misspecification} & \textbf{Possible consequence(s)} & \textbf{Possible correction} \\
		\hline
		\hline
		Misestimation of the total sample size$^{(1)}$ & Bias estimation of SNP heritability \cite[]{gazal2018functional,grotzinger2021pervasive} & Estimation of the effective sample size \\
		\hline
		Differences in per-variant sample sizes & Possible violation of model assumptions (e.g.\ equation \eqref{eq:model}) resulting in poor predictive performance & Imputation using equations \eqref{eq:imputeN} and \eqref{eq:imputeNeff}, and filtering$^{(2)}$   \\
		\hline
		Using imputed dosages for GWAS & Standard deviations of dosages are too small, resulting in overestimated effect sizes and standard errors & See section \ref{sec:imputation} \\
		\hline
		Using imputed dosages for LD computation &  & None required; LD seems correctly estimated (Figure \ref{fig:compare-cor}) \\
		\hline 
		Misestimation of imputation INFO scores & Misuse when filtering or adjusting input parameters based on these & Recomputing from a homogeneous subset \\
		\hline
		Error in summary statistics (e.g.\ allele inversions) & Strong violation of model assumptions, which can result in e.g.\ identifying false-positives in fine-mapping \cite[]{susie} & Quality control \\
		\hline
		Rounding of summary statistics (e.g.\ effect sizes and SEs) & Add unnecessary noise to the data & None, but this has almost no impact on the predictive performance (Figure \ref{fig:simu-rounded}) \\
		\hline 
		Ancestry mismatch between summary statistics and LD & Strong mismatch of LD and allele frequencies, often resulting in divergence of models & Checking ancestry proportions from GWAS summary statistics \cite[]{prive2021using} \\
		\hline
		Any & Possible violation of model assumptions resulting in poor predictive performance & Quality control, using more regularization, and constraining LD to blocks \\
		\hline
	\end{tabular}
	\caption{Overview of possible misspecifications when using GWAS summary statistics, along with possible consequences and corrections.\\
	$^{(1)}$ Examples: using the total number of cases and controls in a meta-analysis of binary traits, a larger effective sample size when using BOLT-LMM summary statistics \cite[]{loh2018mixed}, and a reduced effective sample size when using SAIGE on binary traits with a large prevalence \cite[]{zhou2018efficiently,mbatchou2021computationally}.\\ 
	$^{(2)}$ E.g.\ removing SNPs with an effective sample size less than 0.67 times the 90th percentile of sample size \cite[]{zheng2017ld}.
	\label{tab:overview}}
\end{table}

Here we investigate some of these misspecifications, and propose adjustments to improve the predictive performance of polygenic scores derived from GWAS summary statistics.
We approach this from three different angles.
First, based on additional summary information such as the imputation INFO scores and allele frequencies from the GWAS summary statistics, we refine our previously proposed QC \cite[]{prive2020ldpred2}.
This QC consists in comparing standard deviations (of genotypes) inferred from GWAS summary statistics with the ones computed from a reference panel.
This is useful to check that the input parameters used are consistent with one another. 
This was particularly important for LDpred2-auto, which directly estimates two key model parameters, the SNP heritability and polygenicity, from the data \cite[]{prive2020ldpred2}.
Here we further show that standard deviations of imputed genotypes (allele dosages) are lower than the expected values under Hardy--Weinberg equilibrium.
Second, we investigate possible adjustments to apply to the input parameters of PGS methods using summary statistics, namely the reference LD (linkage disequilibrium) matrix, the GWAS effect sizes, their standard errors and corresponding sample sizes.
For example, we show that GWAS effect sizes computed from imputed dosages are larger in magnitude than when computed from true genotypes.
Third, we introduce two new optional parameters in LDpred2-auto to make it more robust to these types of misspecification.
Note that, in this paper, we use ``robust'' to mean ``similar predictive performance''. 
We also reimplement and use a new version of lassosum, called lassosum2, in which we better handle when per-variant sample sizes are different.
We focus our investigations on LDpred2 and lassosum2 for two reasons. First, multiple studies have shown that LDpred2 and lassosum rank among the best methods for single-trait polygenic prediction \cite[]{mak2017polygenic,prive2020ldpred2,pain2021evaluation,kulm2021systematic}.
Second, lassosum2 now uses the exact same input parameters as LDpred2, which makes it easy for us to test the different QCs and adjustments presented here.
We additionally investigate PRS-CS and SBayesR, two competitive PGS methods \cite[]{ge2019polygenic,lloyd2019improved}, for which we develop some code to convert between the different formats required for the LD matrices and input GWAS summary statistics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Materials and Methods}

\subsection{Data for simulations}

We use the UK Biobank imputed (BGEN) data \cite[]{bycroft2018uk}. 
We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of \cite{bycroft2018uk}).
To get a set of genetically homogeneous individuals, we compute a robust Mahalanobis distance based on the first 16 PCs and further restrict individuals to those within a log-distance of 5 \cite[]{prive2020efficient}.  
This results in 362,307 individuals of Northwestern European ancestry.
We randomly sample 300,000 individuals to form a training set (e.g.\ to run the GWAS), 10,000 individuals to form a validation set (to tune hyper-parameters), and use the remaining 52,307 individuals to form a test set (to evaluate final predictive models).

Among genetic variants on chromosome 22 and with a minor allele frequency larger than 0.01 and an imputation INFO score larger than 0.4 (as reported by the UK Biobank), we sample 40,000 of them according to the inverse of the INFO score density so that they have varying levels of imputation accuracy (Figure \ref{fig:hist-info}).
We read the UK Biobank data into two different datasets using function \texttt{snp\_readBGEN} from R package bigsnpr \cite[]{prive2017efficient}, one by reading the BGEN data as hard-called genotypes at random according to the imputation probabilities, and another one by reading it as dosages (i.e.\ expected values according to the imputation probabilities).
The first dataset is used as what could be the real genotype calls and the second dataset as what would be its imputed version; this design technique was used in \cite{prive2019making}.

\subsection{Data for real analyses}

We also use the UK Biobank data for validation/testing in real data analyses, and use the same individuals of Northwestern European ancestry as described in the previous section. We sample 10,000 individuals to form a validation set and use the remaining 352,307 individuals as test set.
We restrict to the 1,054,315 HapMap3 variants used in the LD reference provided in \cite{prive2020ldpred2}.

To define phenotypes in the UK Biobank, we first map ICD10 and ICD9 codes (UKBB fields 40001, 40002, 40006, 40013, 41202, 41270 and 41271) to phecodes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}.
We also use some continuous phenotypes, namely vitamin D (Data-Field 30890), height (50), BMI (21001), systolic blood pressure (4080), and HDL cholesterol (30760).

To derive polygenic scores, we use published GWAS summary statistics listed in table \ref{tab:sumstats}.
We also use GWAS summary statistics for five disease endpoints from FinnGen\cite{kurki2022finngen} (release 6) and for four continuous outcomes from Biobank Japan \cite[]{sakaue2021cross}.

\begin{table}[h]
	\centering
	\begin{tabular}{|l||c|c|c||c|c|}
		\hline
		Trait & GWAS citation & \begin{tabular}{@{}c@{}}Effective GWAS\\sample size\end{tabular} & \# GWAS variants & \begin{tabular}{@{}c@{}}\# matched variants\\with INFO > 0.4\end{tabular} & Mean INFO \\
		\hline
		Breast cancer (BRCA) [iCOGS] & \cite{michailidou2017association} & ~~87,037 & 11,792,542 & 1,051,242 & 0.841 \\
		Breast cancer (BRCA) [OncoArray] & \cite{michailidou2017association} & 104,442 & 11,792,542 & 1,054,233 & 0.968 \\
		Type 1 diabetes (T1D) [Affymetrix] & \cite{censin2017childhood} & ~~~~~5516  & ~~8,996,866 & ~~~934,712 & 0.885 \\	
		Type 1 diabetes (T1D) [Illumina] & \cite{censin2017childhood} & ~~~~~7982  & ~~8,996,866 & ~~~949,334 & 0.942 \\
		Prostate cancer (PRCA) & \cite{schumacher2018association} & 135,316 & 20,370,946 & ~~~818,400 & 0.969 \\
		Depression (MDD) [without UKBB] & \cite{wray2018genome} & 110,464 & ~~9,874,289 & 1,049,455 & 0.968 \\
		Coronary artery disease (CAD) & \cite{nikpay2015comprehensive} & 129,014 & ~~9,455,778 & 1,052,200 & 0.982 \\
		Vitamin D & \cite{jiang2018genome} & ~~79,366 & ~~2,579,296 & 1,016,935 & NA \\
		\hline
	\end{tabular}
	\caption{Summary of external GWAS summary statistics used. PRCA summary statistics have many variants with a missing INFO score, which we discard. We also restrict to variants with an INFO score larger than 0.4. Note that vitamin D summary statistics do not report INFO scores. \label{tab:sumstats}}
\end{table}


\subsection{Model for summary statistics}

In this paper, we extensively use the following formula
\begin{equation}\label{eq:approx-sd-lin}
S_j = \text{sd}(G_j) \approx \dfrac{\text{sd}(y)}{\sqrt{n_j ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~,
\end{equation}
where $\hat{\gamma}_j$ is the marginal GWAS effect size of variant $j$, $n_j$ is the GWAS sample size associated with variant $j$, $y$ is the vector of phenotypes and ${G}_j$ is the vector of genotypes for variant $j$.
This formula is used in LDpred2 \cite[]{prive2020ldpred2,prive2021high}. Note that, for a binary trait for which logistic regression is used, we have instead
\begin{equation}\label{eq:approx-sd-log}
\text{sd}(G_j) \approx \dfrac{2}{\sqrt{n_j^\text{eff} ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~,
\end{equation}
where $n_j^\text{eff} = \frac{4}{1 / n_j^\text{cases} + 1 / n_j^\text{controls}}$.

It is assumed that the marginal (GWAS) effects follow
\begin{align}
\begin{split}\label{eq:model}
 \hat{\gamma} | S,R,\gamma & \sim \mathcal{N}(S^{-1} R S \gamma, S^{-1} R S^{-1}) ~,\\
 S \hat{\gamma} | S,R,\gamma & \sim \mathcal{N}(R S \gamma, R) ~.
\end{split}
\end{align}
where $R$ is the correlation matrix of genotypes \cite[]{zhu2017bayesian}. 
Then PGS methods aim at inferring $\gamma$, the true causal (per-allele) effects, from $S$, $R$, and $\hat{\gamma}$.
However, in practice, we only have estimates for $S$ and $R$, which causes some model misspecifications.


\subsection{GWAS sample size imputation}\label{sec:imputeN}

We can impute $n_j$ from equation \eqref{eq:approx-sd-lin} using
\begin{equation}\label{eq:imputeN}
n_j \approx \dfrac{\text{var}(y) / \text{var}(G_j) - \hat{\gamma}_j^2}{\text{se}(\hat{\gamma}_j)^2} ~,
\end{equation}
and impute $n_j^\text{eff}$ from equation \eqref{eq:approx-sd-log} using
\begin{equation}\label{eq:imputeNeff}
n_j^\text{eff} \approx \dfrac{4 / \text{var}(G_j) - \hat{\gamma}_j^2}{\text{se}(\hat{\gamma}_j)^2} ~.
\end{equation}
In practice, we also bound these estimates to be between $0.5 \cdot N$ and $1.1 \cdot N$, where $N$ is the total (effective) sample size.
Also note that the estimate of $\text{var}(G_j)$ has to account for the imputation accuracy, i.e.\ use $2 \cdot f_j \cdot (1 - f_j) \cdot \text{INFO}_j$ (Section \ref{sec:imputation}).
In equations \eqref{eq:approx-sd-lin} and \eqref{eq:imputeN}, we estimate $\text{var}(y)$ by the first percentile (robust minimum) of $0.5 \left(N ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2\right)$.

\subsection{New implementation of lassosum in bigsnpr}\label{lassosum2}

Instead of using a regularized version of the correlation matrix $R$ parameterized by $s$, $R_s = (1 - s) R + s I$ (where $0 < s \leq 1$), we use $R_{\delta} = R + \delta I$ (where $\delta > 0$), which makes it clearer that lassosum is also using L2-regularization (therefore elastic-net). 
Then, from \cite{mak2017polygenic}, the solution from lassosum can be obtained by iteratively updating 
\[
\beta_j^{(t)} =
\begin{cases}
\dfrac{\text{sign}\big(u_j^{(t)}\big) \big( \big|u_j^{(t)}\big| - \lambda \big)}{\widetilde{X}_j^T \widetilde{X}_j + \delta} & \text{if } \big|u_j^{(t)}\big| > \lambda ~, \\
0 & \text{otherwise.}
\end{cases}
\]
where 
\[
u_j^{(t)} = r_j - \widetilde{X}_j^T \big( \widetilde{X} \beta^{(t-1)} - \widetilde{X}_j \beta_j^{(t-1)} \big) ~.
\]
Following the notations from \cite{prive2020ldpred2}, denote $\widetilde{X} = \frac{1}{\sqrt{n-1}} C_n G S^{-1}$, where $G$ is the genotype matrix, $C_n$ is the centering matrix and $S$ is the diagonal matrix of standard deviations of the columns of $G$.
Then $\widetilde{X}_j^T \widetilde{X} = R_{j,.} = R_{.,j}^T$ and $\widetilde{X}_j^T \widetilde{X}_j = 1$. Moreover, using the notations from \cite{prive2020ldpred2}, $u_j^{(t)} = \widehat{\beta}_j - R_{.,j}^T \beta^{(t-1)} + \beta_j^{(t-1)}$,
where $r_j = \widehat{\beta}_j =  \dfrac{\widehat{\gamma}_j}{\sqrt{n_j ~ \text{se}(\widehat{\gamma}_j)^2 + \widehat{\gamma}_j^2}}$ and $\widehat{\gamma}_j$ is the GWAS effect of variant $j$ and $n$ is the GWAS sample size \cite[]{mak2017polygenic,prive2021high}.
Then computing $R_{.,j}^T \beta^{(t-1)}$ is the most time-consuming part of each iteration.
To make this faster, instead of computing $R_{.,j}^T \beta^{(t-1)}$ at each iteration ($j$ and $t$), we can start with an initial vector of 0s only (for all $j$) since $\beta^{(0)} \equiv 0$, then update this vector when $\beta_j^{(t)} \neq \beta_j^{(t-1)}$ only. Note that only positions $k$ for which $R_{k,j} \neq 0$ must be updated in this vector $R_{.,j}^T \beta^{(t-1)}$. 
Since bigsnpr v1.10.4, we now also use this updating strategy in LDpred2 (-grid and -auto), which makes it much faster, especially when the polygenicity is small.

In this new implementation of the lassosum model, which we call lassosum2, the input parameters are the correlation matrix $R$, the GWAS summary statistics ($\widehat{\gamma}_j$, $\text{se}(\widehat{\gamma}_j)$ and $n_j$), and the two hyper-parameters $\lambda$ and $\delta$. 
Therefore, except for the two hyper-parameters, lassosum2 uses the exact same input parameters as LDpred2 \cite[]{prive2020ldpred2}.
We try $\delta \in \{0.001, 0.01, 0.1, 1\}$ by default in lassosum2, instead of $s \in \{0.2, 0.5, 0.8, 1.0\}$ in lassosum.
For $\lambda$, the default in lassosum uses a sequence of 20 values equally spaced on a log scale between 0.1 and 0.001. By default in lassosum2, we use a similar sequence of 30 values, but between $\lambda_0$ and $\lambda_0 / 100$ instead, where $\lambda_0 = \max_j \big|\widehat{\beta}_j\big|$ is the minimum $\lambda$ for which no variable enters the model because the L1-regularization is too strong.
To make lassosum2 more robust to different per-variant sample sizes $n_j$, we also introduce per-variant penalty factors $\sqrt{\max_k(n_k) / n_j}$, by which we internally multiply $\lambda$ and $\delta$ to penalize variants with smaller GWAS sample sizes more.
Note that we do not provide an ``auto'' version using pseudo-validation (as in lassosum \cite[]{mak2017polygenic}) since we have not found the pseudo-validation scores to be consistent enough with the predictive performance (Figure \ref{fig:pseudoval}).
Also note that, as in LDpred2, we run lassosum2 genome-wide using a sparse correlation matrix which assumes that variants further away than 3 cM are not correlated.
Contrary to for lassosum, we do not require splitting the genome into independent LD blocks anymore, yet we recommend to do so for robustness in LDpred2, and for extra speed gain (cf.\ Methods section \ref{sec:LD}).

\subsection{LDpred2-low-h2 and LDpred2-auto-rob}\label{sec:robust}

Here we introduce the small changes made to LDpred2 (-grid and -auto) in order to make them more robust.
First, LDpred2-low-h2 simply consists in running LDpred2-grid while testing $h^2$ within $\{0.3, 0.7, 1, 1.4\} \cdot h^2_\text{LDSC}$ (note the added $0.3$ compared to \cite{prive2020ldpred2}), where $h^2_\text{LDSC}$ is the heritability estimate from LD score regression. Indeed, we show in simulations here that using lower values for $h^2$ may provide higher predictive performance in the case of misspecifications (thanks to more shrinkage of the effects).
In simulations, because of the large misspecifications, we use a larger grid over $\{0.01, 0.1, 0.3, 0.7, 1, 1.4\} \cdot h^2_\text{LDSC}$.

For LDpred2-auto, we introduce two new parameters. The first one, \texttt{shrink\_corr}, allows for shrinking off-diagonal elements of the correlation matrix. This is similar to parameter `s' in lassosum (Methods section \ref{lassosum2}), and acts as a means of regularization. We use a value of 0.9 in simulations and 0.95 in real data when running ``LDpred2-auto-rob'' here, and the default value of 1 (with no effect) when running ``LDpred2-auto''.
The second new parameter, \texttt{allow\_jump\_sign}, controls whether variant effect sizes can change sign over two consecutive iterations of the Gibbs sampler. When setting this parameter to false (in the method we refer to as ``LDpred2-auto-rob'' here), this forces the effects to go through 0 before changing sign. This is useful to prevent instability (oscillation and ultimately divergence) of the Gibbs sampler under large misspecifications, and is also useful for accelerating convergence of chains with a large initial value for $p$ (the proportion of causal variants).

\subsection{New LD reference}\label{sec:LD}

We form nearly independent LD blocks using the optimal algorithm developed in \cite{prive2021optimal}.
Note that a new parameter \texttt{max\_r2} has been added to this method since, which controls the maximum single squared correlation allowed outside blocks, which offers an extra guarantee that the splitting is good and makes the function much faster by discarding lots of possible splits.
For different numbers of blocks and maximum number of variants in each block, we use the split that minimizes $\big(C2 \cdot \sqrt{5 + C1}\big)$, where $C1$ is the sum of squared correlations outside the blocks, and $C2$ is the sum of squared sizes of the blocks (Figure \ref{fig:cost-split}).
Having a correlation matrix with independent blocks prevents small errors in the algorithm (e.g.\ the Gibbs sampler in LDpred2) from propagating to too many variants.
It also makes running LDpred2 (and lassosum2) faster, taking e.g.\ 60\% of the initial time (since only 60\% of the initial non-zero values of the correlation matrix are kept).
Note that we also compute the correlations within the same blocks and from the same data for PRS-CS.

We have also developed a new ``compact'' format for the SFBMs (sparse matrices on disk). Instead of using something similar to the standard ``compressed sparse column'' format which stores all $\{i,~x(i, j)\}$ for a given column $j$, we only store the first index $i_0$ and all the contiguous values $\{x(i_0, j),~x(i_0 + 1, j),~\dots\}$ up to the last non-zero value for this column $j$. This makes this format about twice as efficient for both LDpred2 and lassosum2 (in terms of both memory and speed). 
Therefore, using both this new format and the LD blocks should divide computation times by 3 (without counting the faster updating strategy of residuals).

\subsection{Alternative LD reference for FinnGen and Biobank Japan}\label{sec:altLD}

To be used with GWAS summary statistics from FinnGen, we investigate three different LD reference panels.
To define homogeneous ancestry groups in the UK Biobank, we include all individuals within a specific distance to a population center in the PCA space \cite[]{prive2021high,prive2021using}.
We use either the 503 European (including 99 Finnish) individuals from the 1000 Genomes (1000G) data \cite[]{10002015global}, 404 Finnish-like UKBB + the 99 Finnish 1000G individuals (also 503 in total), or the 10,000 UK individuals from the validation set we use in this paper.

To be used with GWAS summary statistics from Biobank Japan, we also investigate three different LD reference panels.
We use either the 504 East Asian (including 104 Japanese) individuals from the 1000G, 400 Japanese-like UKBB + the 104 Japanese 1000G individuals (also 504 in total), or 2041 East Asian UKBB individuals (including the 400 previous Japanese individuals).
For the small LD references (based on \textasciitilde 500 individuals), we restrict to variants with a MAF > 0.02.
For the one based on 2041 individuals, we restrict to MAF > 0.01.
We also construct versions of these LD references with independent LD blocks, as described in the previous section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}

\subsection{Misspecification of per-variant GWAS sample sizes}

We design GWAS simulations where variants have different sample sizes, which is often the case when meta-analyzing GWAS summary statistics from multiple cohorts with different sets of variants \cite[]{wang2021global}.
Using 40,000 variants from chromosome 22 (Methods), we simulate quantitative phenotypes with a heritability of 20\% and 2000 causal variants.
We then randomly divide the 40,000 variants into three groups: for half of the variants, we use 100\% of 300,000 individuals for GWAS, but use only 80\% for one quarter of the variants and 60\% for the remaining quarter. 
We then run C+T, lassosum, lassosum2 (Methods section \ref{lassosum2}), LDpred2-inf, LDpred2(-grid), LDpred2-auto, SBayesR, and PRS-CS-auto \cite[]{prive2019making,mak2017polygenic,prive2020ldpred2,lloyd2019improved,ge2019polygenic} by using either the true per-variant GWAS sample sizes, the total sample size for all variants, or per-variant sample sizes imputed using equation \eqref{eq:imputeN}.
When providing true per-variant GWAS sample sizes, squared correlations between the polygenic scores and the simulated phenotypes are of 0.123 for C+T, 0.160 for lassosum, 0.169 for lassosum2, 0.159 for LDpred2(-grid), 0.140 for LDpred2-auto, 0.141 for LDpred2-inf, 0.138 for SBayesR, and 0.159 for PRS-CS-auto (Figure \ref{fig:simu-misN}, averaging over 10 simulations).
Results when using imputed sample sizes are very similar to when using the true ones.
Note that C+T does not use this sample size information, and that PRS-CS can only be provided with a single value (we use the maximum one).
When using the total GWAS sample size instead of the per-variant sample sizes, predictive performance slightly decreases to 0.158 for lassosum and to 0.164 for lassosum2, but dramatically decreases for LDpred2 with new values of 0.134 for LDpred2-grid, 0.122 for LDpred2-auto, 0.125 for LDpred2-inf (Figure \ref{fig:simu-misN}).
This extreme simulation scenario shows that LDpred2 can be sensitive to the misspecification of per-variant GWAS sample sizes, whereas lassosum (and lassosum2) seems little affected by this.
With 0.141 for SBayesR, predictive performance is actually larger than when using the true per-variant sample sizes.

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.95\textwidth]{simu-misN}}
	\caption{Results for the simulations with sample size misspecification, averaged over 10 simulations for each scenario. Reported 95\% confidence intervals are computed from 10,000 non-parametric bootstrap replicates of the mean. The GWAS sample size is either ``true'' when providing the true per-variant sample size, ``max'' when providing instead the maximum sample size as a unique value to be used for all variants, ``imputed'' (cf.\ equation \eqref{eq:imputeN}), or ``any'' when the method does not use this information (the case for C+T). Red bars correspond to using the LD with independent blocks (Methods section \ref{sec:LD}), which is a requirement for lassosum and PRS-CS.}
	\label{fig:simu-misN}
\end{figure}

We conduct further investigations to explain the results of figure \ref{fig:simu-misN}.
First, the results for LDpred2-auto and SBayesR are similar to LDpred2-inf in these simulations because the internal $p$ estimate of LDpred2-auto (and similarly the proportion of null variants in SBayesR) always continuously increases up to $1$, which makes them behave as an infinitesimal model ($p = 1$).
To overcome this limitation in LDpred2-auto, we introduce two new parameters to make it more robust, and refer to this as ``LDpred2-auto-rob'' here (Methods section \ref{sec:robust}).
The first parameter prevents $p$ from diverging to $1$, while the second shrinks the off-diagonal elements of the LD matrix (a form of regularization). 
Second, for lassosum2, results for a grid of parameters (over $\lambda$ and $\delta$) are quite smooth compared to LDpred2 (Figures \ref{fig:lassosum2-misN} and \ref{fig:ldpred2-misN}). 
In these simulations with misspecified per-variant sample sizes, it seems highly beneficial to use a small value for the SNP heritability hyper-parameter $h^2$ in LDpred2, e.g.\ a value of 0.02 or even 0.002 when the true value is 0.2 (Figure \ref{fig:ldpred2-misN}). 
Indeed, using a small value for this hyper-parameter induces a larger regularization (shrinkage) on the effect sizes.
Here we call ``LDpred2-low-h2'' when running LDpred2(-grid) with a grid of hyper-parameters including these low values for $h^2$.
Results with LDpred2-low-h2 improves from 0.159 to 0.169 when using true sample sizes and from 0.134 to 0.164 when using the maximum sample size.
Finally, we introduce a last change for robustness here: we form independent LD blocks in the LD matrix to prevent small errors in the Gibbs sampler to propagate to too many variants (Methods section \ref{sec:LD}). This change seems to solve convergence issues of LDpred2 in these simulations (Figure \ref{fig:ldpred2-misN}) and further improves predictive performance for all LDpred2 methods (Figure \ref{fig:simu-misN}).

As secondary analysis, we rerun this simulation with a smaller heritability of 4\% instead. While predictive performance are overall much lower, relative performance are less attenuated when using the maximum sample size, otherwise results are highly consistent as before (Figure \ref{fig:simu-misN-smallh2}).
We also try using the shrunk LD matrix from GCTB that is used e.g.\ for SBayesR \cite[]{lloyd2019improved}; in these simulations, higher predictive performance are obtained from LDpred2-auto with this shrunk LD matrix, whereas SBayesR benefit from using LDpred2's windowed LD matrix (Figure \ref{fig:simu-misN-shrunk}).


\subsection{Misspecification when using imputed allele dosages}\label{sec:imputation}

\cite{marchini2010genotype} showed that the IMPUTE INFO measure is highly concordant with the MACH measure $\frac{\text{var}(G_j)}{2 \hat{\theta}_j (1 - \hat{\theta}_j)}$, where $\hat{\theta}_j$ is the estimated allele frequency of $G_j$, the genotypes for variant $j$.
Therefore, when using the expected genotypes from imputation (allele dosages), their standard deviations are often lower than the expected value under Hardy--Weinberg equilibrium, because $\text{INFO}_j \approx \frac{\text{var}(G_j)}{2 \hat{\theta}_j (1 - \hat{\theta}_j)}$.
In simulations (cf.\ Methods section ``Data for simulations''), we verify that $\text{sd}(G_j)^{\text{true}} \approx \text{sd}(G_j)^{\text{imp}} / \sqrt{\text{INFO}_j}$ (Figure \ref{fig:compare-sd}).
As a direct consequence of the lower standard deviation of dosages, we also show that GWAS effect sizes $\hat{\gamma}$ computed from imputed dosages are overestimated: $\hat{\gamma}_j^{\text{true}} \approx \hat{\gamma}_j^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ and $\text{se}(\hat{\gamma}_j)^{\text{true}} \approx \text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ (Figures \ref{fig:compare-beta} and \ref{fig:compare-beta-se}).
This is the first correction of summary statistics we consider in the simulations below.
As a second option, instead of using dosages to compute the GWAS summary statistics, it has been argued that using multiple imputation (MI) would be more appropriate \cite[]{Palmer2016}.
Here MI consists in forming multiple (e.g.\ 20) datasets of hard-called genotypes by sampling them according to the imputation probabilities stored in the BGEN files, performing a GWAS on each of them, and pooling the GWAS estimates.
In simulations, we show that $\hat{\gamma}_j^{\text{MI}} \approx \hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$ and $Z_j^{\text{MI}} \approx Z_j^{\text{imp}} \cdot \text{INFO}_j$, where $Z = \hat{\gamma} / \text{se}(\hat{\gamma})$ (Figure \ref{fig:compare-mi}).
This is the second correction of summary statistics we implement in the simulations below, along with $n_j \cdot \text{INFO}_j$ as the new per-variant sample sizes. 
Finally, we consider an in-between solution as a third correction, using $\hat{\gamma}_j = \hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$, $\text{se}(\hat{\gamma}_j) = \text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$, and $n_j \cdot \text{INFO}_j$ as the per-variant sample sizes. 
Note that we have recomputed INFO scores for the subset of 362,307 European individuals used in this paper since they can differ substantially from the ones reported by the UK Biobank for the whole data (Figures \ref{fig:compare-info} and \ref{fig:compare-maf-info}).

To compare these three corrections, we conduct a simulation using the same 40,000 variants from chromosome 22 as before, where we simulate quantitative phenotypes assuming a heritability of 20\% and 2000 causal variants using the ``true'' dataset (cf.\ Methods section ``Data for simulations'').
We compute GWAS summary statistics from the dosage dataset and use these summary statistics to run LDpred2, lassosum2 and PRS-CS with either no correction of the summary statistics, or with one of the three corrections described above.
The LD references are computed from the validation set using the dataset with the ``true'' genotypes (i.e.\ same as before).
For lassosum2 and LDpred2(-grid), which tune parameters using the validation set, correcting for imputation quality slightly improves predictive performance in these simulations (Figure \ref{fig:simu-info}).
However, correcting for imputation quality can dramatically improve predictive performance for LDpred2-auto, provided the imputation quality is well estimated. 
Moreover, new additions for robustness introduced before, namely LDpred2-low-h2, LDpred2-auto-rob, and forming independent blocks in the LD matrix also improve predictive performance for all corrections (Figure \ref{fig:simu-info}).
However, these corrections do not prove beneficial for PRS-CS-auto (Figure \ref{fig:simu-info}).

When performing similar simulations with a heritability of 4\% (instead of 20\%), correction ``sqrt\_info'' still provides slightly higher predictive performance for all methods (compared to no correction), yet the other two corrections sometimes provide lower predictive performance (Figure \ref{fig:simu-info-smallh2}).
In the real data applications hereinafter, we therefore choose to use the first correction, ``sqrt\_info'', which seems to more consistently provide better results, and is simple because it is somewhat equivalent to post-processing PGS effects by multiplying them by $\sqrt{\text{INFO}}$.


\begin{figure}[!h]
	\centerline{\includegraphics[width=0.95\textwidth]{simu-info}}
	\caption{Results of predictive performance for the simulations using GWAS summary statistics from imputed dosage data, averaged over 10 simulations for each scenario. Reported 95\% confidence intervals are computed from 10,000 non-parametric bootstrap replicates of the mean. Correction ``sqrt\_info'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ and $\text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$.
	Correction ``info'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$  and $n_j \cdot \text{INFO}_j$. Correction ``in\_between'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$, $\text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$, and $n_j \cdot \text{INFO}_j$. Red bars correspond to using the LD with independent blocks (Methods section \ref{sec:LD}), which is a requirement for PRS-CS.}
	\label{fig:simu-info}
\end{figure}


\subsection{Mismatch between LD reference and GWAS summary statistics}

Here we design simulations to understand the impact of using a mismatched LD reference panel, e.g.\ that comes from a different population compared to the one used to compute the GWAS summary statistics.
We use the same simulation setup as before (Methods), i.e.\ using individuals of Northwestern European ancestry from the UK Biobank for training (GWAS), validation (tuning of hyper-parameters), and testing (the final models).
In addition to the LD reference panel of Northwestern European ancestry, we design an alternative reference panel based on 10,000 individuals from South Europe by using the ``Italy'' center defined in \cite{prive2021high}.
Allele frequencies and pairwise correlations are quite similar between these two LD reference panels (Figure \ref{fig:compare-altpop}).
When using this alternative LD reference panel instead of a well-matched one as in the previous sections, squared correlations between the polygenic scores and the simulated phenotypes drop from 0.173 to 0.166 for lassosum2, from 0.168 to 0.159 for LDpred2(-grid), from 0.174 to 0.169 for LDpred2-low-h2, from 0.142 to 0.136 for LDpred2-auto, from 0.162 to 0.147 for LDpred2-auto-rob, from 0.143 to 0.138 for LDpred2-inf, and from  0.163 to 0.155 for PRS-CS-auto (Figure \ref{fig:simu-altpop}, averaging over 10 simulations).
Forming independent LD blocks in these two LD matrices always improve predictive performance, yet again.
We also compute and try using a shrunk LD matrix (from GCTB) for this alternative LD reference panel; again, using this type of LD matrix seems beneficial for LDpred2-auto.
Finally, under the same simulation scenario, but with a smaller simulated heritability of 4\% (instead of 20\%), there remains a small drop in predictive performance when using the alternative LD reference (Figure \ref{fig:simu-altpop-smallh2}).

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.95\textwidth]{simu-altpop}}
	\caption{Results for the simulations with summary statistics with LD matrices based on two different populations. One comes from the same ancestry used for computing the GWAS summary statistics (North-West Europe), while the other one comes from South Europe (alternative LD reference). Reported 95\% confidence intervals are computed from 10,000 non-parametric bootstrap replicates of the mean. Red bars correspond to using the LD with independent blocks (Methods section \ref{sec:LD}), which is a requirement for PRS-CS.}
	\label{fig:simu-altpop}
\end{figure}

\subsection{Application to breast cancer summary statistics}

In this section, we transition to using real data.
Breast cancer GWAS summary statistics are interesting because they include results from two mega analyses \cite[]{michailidou2013large,michailidou2015genome,michailidou2017association}, which means that parameters reported in these GWAS summary statistics, such as INFO scores and sample sizes, are estimated with high precision.
Imputation INFO scores for the OncoArray summary statistics are generally very good (mean of 0.968 after having restricted to HapMap3 variants, Figure \ref{fig:hist-info-brca}) and better than the ones from iCOGS (mean of 0.841, Figure \ref{fig:hist-info-brca2}), probably because the iCOGS chip included around 200K variants only, compared to more than 500K variants for the OncoArray.
For both summary statistics, we compare the standard deviations (of genotypes) inferred from the reported allele frequencies (i.e.\ $\sqrt{2 f (1 - f)}$ where $f$ is the allele frequency, and denoted as sd\_af) versus the ones inferred from the GWAS summary statistics (Equation \eqref{eq:approx-sd-log}, and denoted as sd\_ss).
As shown in figures \ref{fig:brca_onco_qc} and \ref{fig:brca_icogs_qc}, there is a clear trend with sd\_ss being lower than sd\_af as INFO decreases; indeed, using $\text{sd\_ss} / \sqrt{\text{INFO}}$ provides a very good fit for sd\_af, except for some variants of chromosome 6 and 8 for the OncoArray summary statistics. 
Most of these outlier variants are either in region 25-33 Mbp of chromosome 6 or in 8-12 Mbp of chromosome 8 (Figure \ref{fig:hist-bad-pos}), which are two known long-range LD regions \cite[]{price2008long}.
We hypothesize that this is due to using principal components (PCs) that capture LD structure instead of population structure, as covariates in the GWAS \cite[]{prive2020efficient}.
To validate this hypothesis, we simulate a phenotype using HapMap3 variants of chromosome 6 for 10,000 individuals from the UK Biobank, then we run GWAS with or without PC19 as covariate. PC19 from the UK Biobank was previously reported to capture LD structure in region 70-91 Mbp of chromosome 6 \cite[]{prive2020efficient}.
In these simulations, the same bias as in figure \ref{fig:brca_onco_qc}B is observed for the variants in this region (Figure \ref{fig:gwas_bad_pc}), confirming our hypothesis.

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.9\textwidth]{brca_onco_qc}}
	\caption{Standard deviations inferred from the OncoArray breast cancer GWAS summary statistics using equation \eqref{eq:approx-sd-log} (\textbf{A:} Raw or \textbf{B:} dividing them by $\sqrt{\text{INFO}}$) versus the ones inferred from the reported GWAS allele frequencies $f_j$ (using $\sqrt{2 f_j (1 - f_j)}$). Only 100,000 HapMap3 variants are represented, at random.}
	\label{fig:brca_onco_qc}
\end{figure}

Therefore, providing an accurate imputation INFO score is useful for two reasons. First, it allows for correcting for a reduced standard deviation when using imputed data in the QC step we propose, in order to better uncover possible problems with the GWAS summary statistics.
Second, using one of the proposed corrections based on INFO scores may lead to an improved prediction when deriving polygenic scores.
We apply these corrections to the two breast cancer summary statistics. 
In the comparison, we use the QC proposed in \cite{prive2020ldpred2} first (which ends up filtering on MAF here, which we call ``qc1''). We then also filter out the two long-range LD regions of chromosome 6 and 8 for the OncoArray summary statistics and remove around 500 variants when filtering on differences of AFs between summary statistics and the validation dataset (``qc2'').
As for the correction using INFO scores, we use the first correction, ``sqrt\_info'', which is simple because it is equivalent to post-processing PGS effects by multiplying them by $\sqrt{\text{INFO}}$.
Although results for both QC used are very similar, correcting using INFO scores slightly improves predictive performance when deriving polygenic scores based on iCOGS summary statistics (Figure \ref{fig:res_brca_icogs}). 
All other improvements introduced before have little to no effect here, probably because misspecifications are much smaller than in the simulations.

\subsection{Results for other phenotypes}

We use other external GWAS summary statistics for which INFO scores are reported (see Table \ref{tab:sumstats}); they all have a very high mean INFO score (larger than 0.94), except for T1D-affy (0.885).
QC plots comparing standard deviations usually show little deviation from the identity line (after the INFO score correction), except for coronary artery disease (CAD) summary statistics (Figures \ref{fig:brca_icogs_qc}-\ref{fig:t1d_illu_qc}).
We recall that the popular CAD summary statistics used here come from a multi-ancestry GWAS meta-analysis with more than 20\% non-European samples \cite[]{nikpay2015comprehensive,prive2021using}.
In figures \ref{fig:res_cad} and \ref{fig:res_brca_onco}-\ref{fig:res_t1d_aff}, we then provide similar results as figure \ref{fig:res_brca_icogs} for other phenotypes.
For MDD and PRCA, most changes introduced before have little to no impact on predictive performance.
For CAD and T1D, the QC proposed in \cite{prive2020ldpred2} and the additional QC proposed here provides much better predictive performance, especially for LDpred2-auto (and LDpred2-auto-rob) than when using no quality control, showing how important this preliminary step is.

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.85\textwidth]{res-cad}}
	\caption{Variance explained of CAD in the UK Biobank by PGS derived from external summary statistics. These are computed using function \texttt{pcor} of R package bigstatsr where 95\% confidence intervals are obtained through Fisher's Z-transformation; these values are then squared. Red bars correspond to using the LD with independent blocks (Methods), which is a requirement for PRS-CS.}
	\label{fig:res_cad}
\end{figure}

We also investigate results for vitamin D GWAS summary statistics, which do not report INFO scores nor allele frequencies, as opposed to previous ones.
The QC procedure is then less precise and uses allele frequencies from the LD reference (Figure \ref{fig:vitaminD_qc}).
However, these summary statistics do report per-variant sample sizes, which cover a wide range of different values (Figure \ref{fig:hist-N-vitaminD}).
Here we compare using either the maximum sample size or the true per-variant sample sizes when deriving polygenic scores, and an additional QC step ``qc2'' which refers to removing all variants with a per-variant sample size less than 70\% of the maximum one.
When the true per-variant sample sizes are used, the additional ``qc2'' does not seem to be necessary (Figure \ref{fig:res_vitaminD}), which is a bit surprising to us.
When the maximum sample size is used, this ``qc2'' is very important, especially for LDpred2-auto.
Note that, when using the maximum sample size to derive ``sd\_ss'' in ``qc1'' (not the case here; we used the per-variant sample sizes), ``qc1'' would remove variants with underestimated standard deviations due to overestimated sample sizes, which would effectively remove variants with low sample sizes (Figure \ref{fig:qcplot}), similar to the ``qc2'' used here.

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.85\textwidth]{res-vitaminD}}
	\caption{Variance explained of vitamin D in the UK Biobank by PGS derived from external summary statistics. These are computed using function \texttt{pcor} of R package bigstatsr where 95\% confidence intervals are obtained through Fisher's Z-transformation; these values are then squared. Red bars correspond to using the LD with independent blocks (Methods), which is a requirement for PRS-CS.}
	\label{fig:res_vitaminD}
\end{figure}

For all phenotypes, PRS-CS-auto is very robust, whatever the QC procedure used (e.g.\ see the results for CAD, Figure \ref{fig:res_cad}). We believe this is because of the strong regularization used internally. We then run LDpred2-auto-rob for CAD with different shrinkage multiplicative coefficients for the off-diagonal elements of the LD matrix, from 1 (LD matrix unchanged) to 0 (using the identity matrix instead).
When using a strong shrinkage of 0.3 or 0.4, results for LDpred2-auto-rob are similar whatever the QC used (Figure \ref{fig:res_cad_shrinkage}). Results are always best when using ``qc2'', the most stringent QC; then no shrinkage (1) seems needed, while a strong shrinkage make predictive performance drop.
For phenotypes with relatively large genetic effects (e.g.\ vitamin D, Figure \ref{fig:res_vitaminD}), PRS-CS-auto perform much worse, possibly due to using too much regularization.

\subsection{Application to FinnGen and Biobank Japan summary statistics}

Here we investigate the use of different LD reference panels with GWAS summary statistics from two large biobanks of isolated populations.
We use GWAS summary statistics for five disease endpoints from FinnGen\cite{kurki2022finngen} (release 6), namely breast and prostate cancers (BrCa and PrCa), coronary artery disease (CAD), type 1 and type 2 diabetes (T1D and T2D).
These were derived using SAIGE \cite[]{zhou2018efficiently}.
First, for each phenotype, we estimate a global effective sample using the 80th percentile of imputed sample sizes from equation \eqref{eq:imputeNeff}.
This estimation is only 84.7\% for BrCa, 79.1\% for PrCa, 73.1\% for T1D, 64.5\% for T2D, and 61.3\% for CAD, when compared to the effective sample computed from the reported numbers of cases and controls.
We believe this reduction in effective sample size is due to both having related individuals included in the analyses, as well as using SAIGE, as noted in the introduction.
We then compare three different LD reference panels to use with these GWAS summary statistics (Methods section \ref{sec:altLD}).
Interestingly, using the small Finnish LD reference panel composed of 503 individuals only we have defined here seems to consistently provide more predictive polygenic scores than using the large UK one composed of 10,000 individuals or the widely used European subset of the 1000 Genomes (1000G) data (Figure \ref{fig:finngen}).
Note that the PGS here are validated in people of UK-like ancestry in the UK biobank to obtain sufficient sample sizes. 

\begin{figure}[!h]
	\centerline{\includegraphics[width=0.85\textwidth]{res-FIN}}
	\caption{Results for PGS derived from five FinnGen GWAS summary statistics and using three different LD references. Partial correlations are computed using function \texttt{pcor} of R package bigstatsr where 95\% confidence intervals are obtained through Fisher's Z-transformation, then all values are squared to report the phenotypic variance explained by PGS. Red bars correspond to using the LD with independent blocks (Methods), which is a requirement for PRS-CS.}
	\label{fig:finngen}
\end{figure}

We also use GWAS summary statistics for four continuous outcomes from Biobank Japan \cite[]{sakaue2021cross}.
These were derived using BOLT-LMM-inf \cite[]{loh2018mixed}.
First, for each phenotype, we estimate a global power improvement provided by BOLT-LMM by comparing $\chi^2$-statistics (the boost of BOLT-LMM-inf versus linear regression) across genome-wide significant variants, as recommended in \cite{loh2018mixed}.
This estimated power ratio, which corresponds to the increase in effective sample size, is 1.143 for height, 1.039 for HDL cholesterol, 1.025 for BMI, and 1.013 for systolic blood pressure.
We then compare three different LD reference panels to use with these GWAS summary statistics (Methods section \ref{sec:altLD}).
Interestingly, when looking at height and to some extent at HDL cholesterol where we could get the best predictive performance, using the smaller Japanese LD reference we have defined here seems to provide more predictive PGS than using the one using a larger set of East Asian individuals from the UKBB or the widely used East Asian subset of the 1000 Genomes (1000G) data (Figure \ref{fig:bbj}).
Note that the PGS here are validated in people of broad East Asian ancestry in the UK biobank and for continuous outcomes  to obtain sufficient sample sizes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

Here we have investigated misspecifications in GWAS summary statistics, focusing particularly on the impact of sample size heterogeneity and imputation quality, and the application to polygenic scores (PGS) methods.
Previously, we proposed a quality control (QC) based on comparing standard deviations (of genotypes) inferred from GWAS summary statistics with the ones computed from a reference panel \cite[]{prive2020ldpred2}.
Here we show that we can refine this QC by deriving the latter directly from the reported allele frequencies in the GWAS summary statistics, and by correcting the former using imputation INFO scores.
Using this refined QC, we are able to identify a potential issue with how principal components were derived in a GWAS of breast cancer. Fortunately, this has practically no effect on the predictive performance of the derived polygenic scores.
Additional QC can also be performed, e.g.\ comparing reported GWAS allele frequencies with the ones from the LD reference panel, e.g.\ to detect genotyping errors or allele inversions.
We perform this additional QC as part of ``qc2'' here. 
One can also run other QC tools such as DENTIST \cite[]{chen2021improved}, and also infer ancestry proportions from summary statistics to make sure these are matching with the LD reference used \cite[]{prive2021using}. 

Note that, in this study, we mostly use GWAS summary statistics that include extended information (e.g.\ INFO scores and allele frequencies), yet most GWAS summary statistics do not provide such exhaustive information \cite[]{macarthur2021workshop}.
We acknowledge that, in the case of a meta-analysis from multiple studies, providing a single INFO score per variant may not be possible.
Solutions such as using a weighted averaged INFO score might be worth exploring in future studies.
Nevertheless, this quality control could be performed within each study before meta-analyzing results, to make sure that resulting summary statistics have the best possible quality for follow-up analyses such as deriving polygenic scores.
Another information, the effective sample size per variant, is often missing from GWAS summary statistics. 
Sometimes, it can even be challenging to recover the total effective sample size from large meta-analyses.
We recall that, when some studies have an imbalanced number of cases and controls, the total effective sample size of their meta-analysis should not be computed from the total numbers of cases and controls overall, but instead from the sum of the effective sample sizes of each study \cite[]{grotzinger2021pervasive}.
Indeed, take the extreme example of meta-analyzing two studies, one with 1000 cases and 0 controls, and another one with 0 cases and 1000 controls, then the effective sample size of the meta-analysis is 0, not 2000.
Misspecifying the GWAS sample size can lead to serious issues such as misestimating the SNP heritability \cite[]{grotzinger2021pervasive}.
Fortunately, an overestimated sample size can be detected from the QC plot we propose, where the slope is then less than 1 for case-control studies using logistic regression.
Here we have used this strategy to estimate reduced effective sample sizes in FinnGen GWAS summary statistics.

We have assessed the impact of these misspecifications in GWAS summary statistics on the predictive performance of some polygenic score methods.
Using both the Bayesian LDpred2 models \cite[]{prive2020ldpred2} and our reimplementation of the frequentist lassosum model \cite[]{mak2017polygenic} for deriving polygenic scores, we have introduced and investigated some changes to possibly make these models more robust to misspecifications.
Overall, these changes provided large improvements of predictive performance in the simulations with large misspecifications.
The proposed quality controls on GWAS summary statistics also provided better predictive performance for CAD, T1D, and vitamin D.
However, these changes had limited effect when applied to some other real GWAS summary statistics, which is both unfortunate but also reassuring because it means that these GWAS summary statistics are of particularly good quality for follow-up analyses such as deriving polygenic scores.

In conclusion, we recommend adopting these changes, i.e.\ performing the (refined) QC proposed here, forming independent LD blocks in the LD matrix, and using more regularization when needed. 
We also recommend using well-matched LD reference panels. 
More regularization can be achieved by testing additional smaller values for the heritability parameter in LDpred2-grid, and using the two new parameters introduced here in LDpred2-auto (Methods section \ref{sec:robust}). 
Note that LD blocks are already widely used by several methods, such as lassosum and PRS-CS, because they allow for processing smaller matrices at once \cite[]{mak2017polygenic,ge2019polygenic}.
Imposing independent blocks on the LD matrix could result in further misspecifications \cite[]{zhou2021fast}, but here we have shown that well defined blocks can actually make PGS methods more robust.
PRS-CS is currently one of the most robust PGS methods; for example, it can use the (small) 1000 Genomes data as LD reference \cite[]{ge2019polygenic}, and can even use a European LD reference panel with multi-ancestry GWAS summary statistics \cite[]{wang2021global}.
We believe this is made possible by the use of a strong regularization in PRS-CS ($\phi^{-1} \psi_j^{-1} \ge 1$, which would approximately correspond to using $s=0.5$ in lassosum, $\delta = 1$ in lassosum2, and the new parameter $\texttt{shrink\_corr}=0.5$ in LDpred2-auto).
Using enough regularization is good for robustness, but note that using too much regularization can also damage predictive performance.
To address this limitation, we recommend to rely on a proper QC and choice of ancestry-matched LD instead of on too much regularization.
We would like to encourage large biobanks, such as FinnGen and Biobank Japan, to provide LD reference matrices matching the large GWAS summary statistics they provide, ideally based on the same large number of individuals. 
As a future research direction, we are interested in using multi-ancestry-matched LD matrices to use with multi-ancestry GWAS summary statistics in order to improve polygenic prediction in all ancestries.
It would also be useful to investigate the impact of the QC, well-matched LD reference panels and other adjustments we propose here on other (non-PGS) methods, for which consistency and robustness are likely to be very important as well \cite[]{chen2021improved}.
For example, we are interested in assessing the impact of these misspecifications on the inference of disease architecture parameters in some future work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
%\vspace*{3em}

\section*{Code and data availability}

All code used for this paper is available at \url{https://github.com/privefl/paper-misspec/tree/master/code}.
We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.

The latest version of R package bigsnpr can be installed from GitHub, and a recent enough version can be installed from CRAN.
A tutorial on running LDpred2 and lassosum2 using R package bigsnpr is available at \url{https://privefl.github.io/bigsnpr/articles/LDpred2.html}.

We have recomputed the allele frequencies and imputation INFO scores within the European subset used here and across all imputed variants in the UK Biobank, and made them available at \url{https://doi.org/10.6084/m9.figshare.16635388}.
We have formed independent LD blocks within the Northwestern European LD references provided in \cite{prive2020ldpred2}, and made these updated versions available at \url{https://doi.org/10.6084/m9.figshare.19213299}.

\section*{Acknowledgements}

Authors thank Timothy Shin Heng Mak, Shing Wan Choi, and Matthew Stephens for helpful discussions. 
Authors also thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024.

\section*{Funding}

F.P.\ and B.J.V.\ are supported by the Danish National Research Foundation (Niels Bohr Professorship to Prof. John McGrath) and by a Lundbeck Foundation Fellowship (R335-2019-2339 to B.J.V.).

\section*{Declaration of Interests}

B.J.V.\ is on Allelica's international advisory board.
The other authors have no competing interests to declare.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\vspace*{3em}

\bibliographystyle{ajhg}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
