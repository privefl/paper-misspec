%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{xurl}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=1.5cm,rmargin=1.5cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}

\renewcommand{\arraystretch}{1.3}

\usepackage{xr}
\externaldocument{paper-misspec-supp}

%\linenumbers
%\doublespacing
\onehalfspacing
%\usepackage[authoryear]{natbib}
\usepackage{natbib} \bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm}
\usepackage{algpseudocode}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=0.9\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}


\title{Identifying and correcting multiple sources of misspecification\\in GWAS summary statistics for polygenic scores}
\author{Florian Priv\'e,$^{\text{1,}*}$ Julyan Arbel,$^{\text{2}}$ Hugues Aschard,$^{\text{3,4}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,5}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-Based Research, Aarhus University, Aarhus, 8210, Denmark. \\
\noindent$^{\text{\sf 2}}$Univ.\ Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, 38000, France. \\
\noindent$^{\text{\sf 3}}$Department of Computational Biology, Institut Pasteur, Paris, 75015, France. \\
\noindent$^{\text{\sf 4}}$Program in Genetic Epidemiology and Statistical Genetics, Harvard T.H. Chan School of Public Health, Boston, MA, 02115, USA. \\
\noindent$^{\text{\sf 5}}$Bioinformatics Research Centre, Aarhus University, Aarhus, 8000, Denmark. \\
\noindent$^\ast$To whom correspondence should be addressed.\\

\noindent Contact: \url{florian.prive.21@gmail.com}

\vspace*{5em}

\abstract{
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Contrary to individual-level genotypes and phenotypes, summary statistics from genome-wide association studies (GWAS) are widely available.
Therefore, they have been extensively used e.g.\ to derive polygenic scores (PGS).
However, GWAS summary statistics come with uneven qualities, such as the imputation qualities of each variant reported. 
There is also some heterogeneity in the methods used for performing the individual GWAS and their meta-analyses, as well as the information reported in the resulting summary statistics.
Moreover, many PGS methods such as PRS-CS, SBayesR, and LDpred2 \cite[]{ge2019polygenic,lloyd2019improved,prive2020ldpred2} use Bayesian models, which can be sensitive to model misspecifications \cite[]{WALKER20131621,miller2018robust}.
Previously, to make sure that input parameters passed to LDpred2 were consistent with its modeling assumptions, we proposed a quality control (QC) based on comparing standard deviations derived from GWAS summary statistics with the ones from a reference panel \cite[]{prive2020ldpred2}.
This was particularly important for LDpred2-auto, which also estimates key model parameters from the data directly.

Here, we investigate some of the possible misspecifications that come with GWAS summary statistics. 
We aim to identify and correct multiple sources of misspecification in the summary statistics in order to improve the predictive performance of polygenic scores.
We approach this from three different angles.
First, based on additional information such as the imputation INFO scores and allele frequencies from the GWAS summary statistics, we refine our previously proposed QC \cite{prive2020ldpred2}.
For instance, we show that standard deviations of imputed genotypes (allele dosages) are lower than the expected values under Hardy-Weinberg equilibrium.
Second, we investigate possible corrections to apply to the input parameters of polygenic methods, namely the reference LD (linkage disequilibrium) matrix, the GWAS effect sizes, their standard errors and the corresponding sample sizes.
For example, we show that GWAS effect sizes computed from imputed dosages are larger in magnitude compared to if true genotypes were available.
Third, we introduce two new optional parameters in LDpred2-auto to make it more robust to these types of misspecification.
We focus our investigations on LDpred2 and lassosum for two reasons. First, multiple studies have shown that LDpred2 and lassosum are consistently ranking best among methods for polygenic prediction \cite[]{mak2017polygenic,prive2020ldpred2,pain2021evaluation,kulm2021systematic}.
Second, we reimplement and use a new version of lassosum, called lassosum2, that uses the exact same input parameters as LDpred2, which makes it easy for us to test the QCs and corrections presented here.
We perform our investigations using simulations first, then we use public summary statistics while restricting to the widely-used HapMap3 variants, finally we investigate two alternative sets with more variants.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}

\subsection{Misspecification of GWAS sample sizes}

We design simulations where variants have different GWAS sample sizes, which is often the case when meta-analyzing GWAS from multiple cohorts without the same genome coverage.
Using 40,000 variants from chromosome 22 (Methods), we simulate quantitative phenotypes with a heritability of 20\% and 2000 causal variants.
We then divide the 40,000 variants into three groups: for half of the variants, we use 100\% of 300,000 individuals for GWAS, but use only 80\% for one quarter of variants and 60\% for the remaining quarter. 
We then run C+T, lassosum, lassosum2 (Methods), LDpred2-inf, LDpred2(-grid), and LDpred2-auto \cite[]{prive2019making,mak2017polygenic,prive2020ldpred2} by using either the true per-variant GWAS sample sizes, the total sample size, or imputed sample sizes. 
Note that we initially included PRS-CS and SBayesR in our comparison \cite[]{ge2019polygenic,lloyd2019improved}. However, results for SBayesR always diverged and the overlap with the LD reference provided for PRS-CS was too small.
Averaged over 10 simulations, when providing true per-variant GWAS sample sizes, squared correlations between the polygenic scores and the simulated phenotypes are of 0.123 for C+T, 0.161 for lassosum, 0.169 for lassosum2, 0.159 for LDpred2(-grid), 0.140 for LDpred2-auto, and 0.141 for LDpred2-inf (Figure \ref{fig:simu-misN}).
Results when using imputed (instead of true) sample sizes are quite similar.
Note that C+T does not use this sample size information.
When using the total GWAS sample size instead of the per-variant sample sizes, predictive performance slightly decreases to 0.157 for lassosum and to 0.163 for lassosum2, but dramatically decreases for LDpred2 with new values of 0.134 for LDpred2-grid, 0.119 for LDpred2-auto, and 0.123 for LDpred2-inf (Figure \ref{fig:simu-misN}).
This extreme simulation scenario shows that LDpred2 can be sensitive to GWAS sample size misspecification, whereas lassosum (and lassosum2) seems little affected by this.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.95\textwidth]{simu-misN}}
	\caption{Results for the simulations with sample size misspecification, averaged over 10 simulations for each scenario. Reported 95\% confidence intervals are computed from 10,000 non-parametric bootstrap replicates of the mean. The GWAS sample size is ``true'' when providing the true per-variant sample size, ``max'' when providing instead the maximum sample size as a unique value to be used for all variants,  ``imputed'' (Methods), or ``any'' when the method does not use this information (the case for C+T). Red bars correspond to using the LD with independent blocks (Methods).}
	\label{fig:simu-misN}
\end{figure}

We conduct further investigations to explain results of figure \ref{fig:simu-misN}.
First, the results for LDpred2-auto are the same as with LDpred2-inf because it always converges to an infinitesimal model ($p = 1$) in these simulations.
To solve this limitation, we introduce two new parameters to make LDpred2-auto more robust, referred to as ``LDpred2-auto-rob'' here (Methods).
Second, for lassosum2, results for a grid of parameters (over $\lambda$ and $\delta$) are quite smooth compared to LDpred2 (Figures \ref{fig:lassosum2-misN} and \ref{fig:ldpred2-misN}). 
In these simulations with misspecified sample sizes, it seems highly beneficial to use a small value for the SNP heritability hyper-parameter $h^2$ in LDpred2, e.g.\ a value of 0.02 or even 0.002 when the true value is 0.2 (Figure \ref{fig:ldpred2-misN}). 
Indeed, using a small value for this hyper-parameter induces a larger regularization (shrinkage) on the effect sizes.
When running LDpred2(-grid) with a grid of hyper-parameters including these low values for $h^2$, we refer to this as ``LDpred2-low-h2'' here.
Results with LDpred2-low-h2 improves from 0.159 to 0.169 when using true sample sizes and from 0.134 to 0.163 when using the maximum sample size.
Finally, we introduce a last change for robustness here: we form independent LD blocks in the LD matrix to prevent small errors in the Gibbs sampler to propagate to too many variants (Methods). This change seems to solve convergence issues of LDpred2 in these simulations (Figure \ref{fig:ldpred2-misN}) and further improves predictive performance for all LDpred2 methods (Figure \ref{fig:simu-misN}).


\subsection{When using allele dosages from imputation}

\cite{marchini2010genotype} showed that the IMPUTE INFO measure is highly concordant with the MACH measure $\hat{r}_j^2 = \frac{\text{var}(G_j)}{2 \hat{\theta}_j (1 - \hat{\theta}_j)}$, where $\hat{\theta}_j$ is the estimated allele frequency of $G_j$, the genotypes for variant $j$.
Therefore, when using the expected genotypes from imputation (dosages), their standard deviations are often lower than the expected value under Hardy-Weinberg equilibrium, because $\text{INFO}_j \approx \frac{\text{var}(G_j)}{2 \hat{\theta}_j (1 - \hat{\theta}_j)}$.
In simulations (cf.\ Methods section ``Data for simulations''), we verify that $\text{sd}(G_j)^{\text{true}} \approx \text{sd}(G_j)^{\text{imp}} / \sqrt{\text{INFO}_j}$ (Figure \ref{fig:compare-sd}).
We also show that GWAS effect sizes $\hat{\gamma}$ computed from imputed dosages are over-estimated: $\hat{\gamma}_j^{\text{true}} \approx \hat{\gamma}_j^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ and $\text{se}(\hat{\gamma}_j)^{\text{true}} \approx \text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ (Figures \ref{fig:compare-beta} and \ref{fig:compare-beta-se}).
This is the first correction of summary statistics we consider in the simulations below. 
Note that we recompute INFO scores for the subset of 362,307 European individuals used in this paper as they can differ substantially from the ones reported by the UK Biobank for the whole data (Figure \ref{fig:compare-info}).
As a second option, instead of using dosages to compute the GWAS summary statistics, it has been argued that using multiple imputation (MI) would be more appropriate \cite[]{Palmer2016}.
In simulations, we show that $\hat{\gamma}_j^{\text{MI}} \approx \hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$ and $Z_j^{\text{MI}} \approx Z_j^{\text{imp}} \cdot \text{INFO}_j$, where $Z = \hat{\gamma} / \text{se}(\hat{\gamma})$ (Figure \ref{fig:compare-mi}).
This is the second correction of summary statistics we implement in the simulations below, along with $n_j = N \cdot \text{INFO}_j$. 
Finally, we consider an in-between solution as a third correction, using $\hat{\gamma}_j = \hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$, $\text{se}(\hat{\gamma}_j) = \text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$, and $n_j = N \cdot \text{INFO}_j$.

Using 40,000 variants from chromosome 22, we simulate quantitative phenotypes assuming a heritability of 20\% and 2000 causal variants using the ``true'' dataset (cf.\ Methods section ``Data for simulations'').
We compute GWAS summary statistics from the dosage dataset and use these summary statistics to run LDpred2 and lassosum2 with either no correction of the summary statistics, or with one of the three corrections described above.
The LD reference used by LDpred2 and lassosum2 is computed from the validation set using the dataset with the ``true'' genotypes.
For lassosum2 and LDpred2(-grid) which tune parameters using the validation set, correcting for imputation quality slightly improves predictive performance in these simulations (Figure \ref{fig:simu-info}).
However, correcting for imputation quality can dramatically improve predictive performance for LDpred2-auto. 
Moreover, new additions for robustness introduced before, namely LDpred2-low-h2, LDpred2-auto-rob, and forming independent blocks in the LD matrix also improve predictive performance for all corrections (Figure \ref{fig:simu-info}).

In the real data applications hereinafter, we choose to use the first correction, ``sqrt\_info'', which is simple because it is equivalent to post-processing PGS effects by multiplying them by $\sqrt{\text{INFO}}$.


\begin{figure}[h]
	\centerline{\includegraphics[width=0.95\textwidth]{simu-info}}
	\caption{Results of predictive performance for the simulations using GWAS summary statistics from imputed dosage data, averaged over 10 simulations for each scenario. Reported 95\% confidence intervals are computed from 10,000 non-parametric bootstrap replicates of the mean. Correction ``sqrt\_info'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$ and $\text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$.
	Correction ``info'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$  and $N \cdot \text{INFO}_j$. Correction ``in\_between'' corresponds to using $\hat{\gamma}_j^{\text{imp}} \cdot \text{INFO}_j$, $\text{se}(\hat{\gamma}_j)^{\text{imp}} \cdot \sqrt{\text{INFO}_j}$, and $N \cdot \text{INFO}_j$. Red bars correspond to using the LD with independent blocks (Methods).}
	\label{fig:simu-info}
\end{figure}


\subsection{Application to breast cancer summary statistics}

Breast cancer summary statistics are interesting because they include results from two mega analyses \cite[]{michailidou2013large,michailidou2015genome,michailidou2017association}, which means there is some larger precision in the parameters reported, such as the INFO scores and the sample sizes.
Imputation INFO scores for the OncoArray summary statistics (after having restricted to HapMap3 variants) are generally very good (Figure \ref{fig:hist-info-brca}) and better than the ones from iCOGS (Figure \ref{fig:hist-info-brca2}), probably because the chip used included around 200K variants only, compared to more than 500K variants for the OncoArray.
For both summary statistics, we first compare the standard deviations inferred from the reported allele frequencies (i.e.\ $\sqrt{2 f (1 - f)}$ where $f$ is the allele frequency, and denoted as sd\_af) versus the ones inferred from the GWAS summary statistics (Equation \eqref{eq:approx-sd-log}, and denoted as sd\_ss).
When coloring by INFO scores, we see a clear trend with sd\_ss being lower than sd\_af as INFO decreases; indeed, using $\text{sd\_ss} / \sqrt{\text{INFO}}$ provides a very good fit for sd\_af, except for some variants of chromosome 6 and 8 for the OncoArray summary statistics (Figures \ref{fig:brca_onco_qc} and \ref{fig:brca_icogs_qc}). Most of these outlier variants are in regions 25-33 Mbp of chromosome 6 and 8-12 Mbp of chromosome 8 (Figure \ref{fig:hist-bad-pos}), which are two known long-range LD regions \cite[]{price2008long}.
We hypothesize that this is due to using principal components (PCs) as covariates in GWAS that capture LD structure instead of population structure \cite[]{prive2020efficient}.
To validate this hypothesis, we simulate a phenotype using HapMap3 variants of chromosome 6 for 10,000 individuals from the UK Biobank, then we run GWAS with or without PC19 as covariate. PC19 from the UK Biobank was previously reported to capture LD structure in region 70-91 Mbp of chromsome 6 \cite[]{prive2020efficient}.
In these simulations, the same bias as in figure \ref{fig:hist-bad-pos}B is observed for the variants in this region (Figure \ref{fig:gwas_bad_pc}), confirming our hypothesis.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.95\textwidth]{brca_onco_qc}}
	\caption{Standard deviations inferred from the OncoArray breast cancer GWAS summary statistics (Equation \ref{eq:approx-sd-log}) versus the ones inferred from the reported GWAS allele frequencies ($\sqrt{2 f (1 - f)}$). Only 100,000 HapMap3 variants are represented, at random.}
	\label{fig:brca_onco_qc}
\end{figure}

Therefore, providing an accurate imputation INFO score is important for two reasons. First, it allows for correcting for a reduced standard deviation when using imputed data in the QC step we propose, in order to better uncover problems with the summary statistics.
Second, using one of the proposed corrections may lead to an improved prediction when deriving polygenic scores.
We apply this correction to the two breast cancer summary statistics. We first compare the standard QC proposed in \cite{prive2020ldpred2} (which ends up filtering on MAF here, which we call ``qc1''). We then also filter out the two long-range LD regions of chromosome 6 and 8 for the OncoArray summary statistics and remove around 500 variants when filtering on differences of MAFs between summary statistics and the validation dataset (``qc2'').
As for the correction for the INFO scores, we use the first correction, ``sqrt\_info'', which is simple because it is equivalent to post-processing PGS effects by multiplying them by $\sqrt{\text{INFO}}$.
Although results for both QC used are very similar, correcting for the INFO score slightly improves prediction when deriving polygenic scores based on iCOGS summary statistics (Figure \ref{fig:res_brca}). 
All other improvements introduced before have little or no effect here, probably because misspecifications are much smaller than in the simulations.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.95\textwidth]{res-brca}}
	\caption{Raw partial correlations (for \textit{all} models) for predicting breast cancer in the UK Biobank when using either the OncoArray or the iCOGS summary statistics. These are computed using function \texttt{pcor} of R package bigstatsr where 95\% confidence intervals are obtained through Fisher's Z-transformation.}
	\label{fig:res_brca}
\end{figure}

\subsection{Other phenotypes and larger sets of variants}

We use external summary statistics for which INFO scores are reported (Table \ref{tab:sumstats}); they all have a very high mean INFO score (larger than 0.94), except for BRCA-iCOGS (0.841) and T1D-affy (0.885).
QC plots comparing standard deviations usually show little deviation from $x=y$ (after the INFO score correction), except for coronary artery disease (CAD) summary statistics (Figures \ref{fig:brca_icogs_qc}-\ref{fig:t1d_illu_qc}).
We show previous results as figure \ref{fig:res_brca} for other phenotypes in figures \ref{fig:res_cad}-\ref{fig:res_t1d}; most changes introduced before have little or no impact on the predictions, except for the second quality control performed for CAD when using LDpred2-auto (Figure \ref{fig:res_cad}).

We then introduce two new sets of variants as possible replacement of HapMap3 variants (Methods).
These sets include more variants (more than 2M), therefore possibly of lower quality on average. 
We show results with these two new sets of variants (Methods) in figures \ref{fig:res_brca_all}-\ref{fig:res_t1d_all}.
Using the ``maxtag'' set generally provides larger predictive performance than using HapMap3 variants, especially when predicting prostate cancer (Figure \ref{fig:res_prca_all}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

We have investigated misspecifications in GWAS summary statistics, focusing on the impact of sample size heterogeneity and imputation quality.
Previously, we proposed a quality control (QC) based on comparing standard deviations derived from GWAS summary statistics with the ones from a reference panel \cite[]{prive2020ldpred2}.
Here we show that we can refine this quality control by deriving the latter directly from the reported allele frequencies in the GWAS summary statistics, and by correcting the former using the GWAS imputation INFO scores (e.g.\ see figure \ref{fig:brca_onco_qc}).
Using this refined QC, we are able to identify a potential issue with how principal components were derived in a set of breast cancer summary statistics. Fortunately, this has practically no effect on the predictive performance of the derived polygenic scores.
Additional QC can also be performed, e.g.\ comparing reported GWAS allele frequencies with the ones from the LD reference panel, e.g.\ to detect genotyping or allelic errors.
We do perform this additional QC as part of ``qc2'' here, and also when designing the large set of variants from the UK Biobank (Methods). 
One can also run other QC tools such as DENTIST \cite[]{chen2021improved}. 

Note that, in this study, we use summary statistics that include extended information (e.g.\ INFO scores and allele frequencies), yet most GWAS summary statistics do not. 
We acknowledge that, in the case of a meta-analysis from multiple studies, providing a single INFO score per variant may not be possible; would a weighted averaged INFO score work?
Nevertheless, this quality control could be easily performed within each study before pooling results, to make sure that summary statistics have the best possible quality for follow-up analyses such as deriving polygenic scores.
Another information, the effective sample size per variant, is often missing from GWAS summary statistics. 
Sometimes, it can even be challenging to recover the total effective sample size from large meta-analyses.
We recall that if some studies of a meta-analysis have an imbalanced number of cases and controls, the global effective sample size should not be computed from the total numbers of cases and controls overall, but instead from the sum of the effective sample sizes of each study.
Indeed, take the extreme example of meta-analyzing two studies, one with 1000 cases and 0 controls, and another one with 0 cases and 1000 controls, then the effective sample size of the meta-analysis is 0, not 2000.
Fortunately, an overestimated sample size can be detected from the QC plot we propose, where the slope is then less than 1 for case-control studies using logistic regression; otherwise the standard deviation of the phenotype is also needed (Equation \ref{eq:approx-sd-lin}), but can be estimated \cite[]{prive2020ldpred2}.

We have assessed the impact of these misspecifications in GWAS summary statistics on the predictive performance of some polygenic score methods.
Using both the Bayesian LDpred2 models \cite[]{prive2020ldpred2} and our reimplementation of the frequentist lassosum model \cite[]{mak2017polygenic} for deriving polygenic scores, we have introduced and investigated some changes to possibly make these models more robust to misspecifications.
Overall, these changes have provided large improvements of predictive performance in simulations with large misspecifications. However, they have almost no effect when using the real GWAS summary statistics we chose, except for breast cancer and coronary artery disease summary statistics.
Although these results are somewhat unfortunate, they are reassuring because it means that the summary statistics we use in this study are usually of good quality for follow-up analyses such as deriving polygenic scores.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Materials and Methods}

\subsection{Data for simulations}

We use the UK Biobank imputed (BGEN) data \cite[]{bycroft2018uk}. 
We restrict individuals to the ones used for computing the principal components (PCs) in the UK Biobank (Field 22020). These individuals are unrelated and have passed some quality control including removing samples with a missing rate on autosomes larger than 0.02, having a mismatch between inferred sex and self-reported sex, and outliers based on heterozygosity (more details can be found in section S3 of \cite{bycroft2018uk}).
To get a set of genetically homogeneous individuals, we compute a robust Mahalanobis distance based on the first 16 PCs and further restrict individuals to those within a log-distance of 5 \cite[]{prive2020efficient}.  
This results in 362,307 individuals.
We sample 300,000 individuals to form a training set (e.g.\ to run GWAS), 10,000 individuals to form a validation set (to tune hyper-parameters), and use the remaining 52,307 individuals to form a test set (to evaluate final predictive models).

Among genetic variants on chromosome 22 and with a minor allele frequency larger than 0.01 and an imputation INFO score larger than 0.4 (as reported by the UK Biobank), we sample 40,000 of them according to the inverse of the INFO score density so that they have varying levels of imputation accuracy (Figure \ref{fig:hist-info}).
We read the UK Biobank data into two different datasets using function \texttt{snp\_readBGEN} from R package bigsnpr \cite[]{prive2017efficient}, one by reading the BGEN data at random according to imputation probabilities, and another one reading it as dosages (i.e.\ expected values according to imputation probabilities).
The first dataset is used as what could be the real genotype calls and the second dataset as what would be its imputed version; this design technique was used in \cite{prive2019making}.

\subsection{Data for real analyses}

We also use the UK Biobank data, and use the same individuals as described in the previous section. We sample 10,000 individuals to form a validation set and use the remaining 352,307 individuals as test set.
We restrict to the genetic variants to the 1,054,315 HapMap3 variants used in the LD reference provided in \cite{prive2020ldpred2}.
We also try two new sets of variants (see next section).

To define phenotypes in the UK Biobank, we first map ICD10 and ICD9 codes (UKBB fields 40001, 40002, 40006, 40013, 41202, 41270 and 41271) to phecodes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}.
We use published GWAS summary statistics listed in table \ref{tab:sumstats} to derive polygenic scores.

\begin{table}[h]
	\centering
	\begin{tabular}{|l||c|c|c||c|c|}
		\hline
		Trait & GWAS citation & \begin{tabular}{@{}c@{}}Effective GWAS\\sample size\end{tabular} & \# GWAS variants & \begin{tabular}{@{}c@{}}\# matched variants\\with INFO > 0.4\end{tabular} & Mean INFO \\
		\hline
		Breast cancer (BRCA) [iCOGS] & \cite{michailidou2017association} & ~~87,037 & 11,792,542 & 1,051,242 & 0.841 \\
		Breast cancer (BRCA) [OncoArray] & \cite{michailidou2017association} & 104,442 & 11,792,542 & 1,054,233 & 0.968 \\
		Type 1 diabetes (T1D) [Affymetrix] & \cite{censin2017childhood} & ~~~~~5516  & ~~8,996,866 & ~~~934,712 & 0.885 \\	
		Type 1 diabetes (T1D) [Illumina] & \cite{censin2017childhood} & ~~~~~7982  & ~~8,996,866 & ~~~949,334 & 0.942 \\
		Prostate cancer (PRCA) & \cite{schumacher2018association} & 135,316 & 20,370,946 & ~~~818,400 & 0.969 \\
		Depression (MDD) [without UKBB] & \cite{wray2018genome} & 110,464 & ~~9,874,289 & 1,049,455 & 0.968 \\
		Coronary artery disease (CAD) & \cite{nikpay2015comprehensive} & 129,014 & ~~9,455,778 & 1,052,200 & 0.982 \\
		\hline
	\end{tabular}
	\caption{Summary of external GWAS summary statistics used. PRCA summary statistics have many variants with a missing INFO score, which we discard.\label{tab:sumstats}}
\end{table}


\subsection{Two new sets of variants}

We also design two larger sets of imputed variants to compare against using only HapMap3 variants for prediction. 
Following \cite{prive2021high}, we first restrict to UKBB variants with MAF > 0.01 and INFO > 0.3.
We then compile frequencies and imputation INFO scores from other datasets, iPSYCH and summary statistics for breast cancer, prostate cancer, coronary artery disease, type-1 diabetes and depression \cite[]{bybjerg2020ipsych2015,michailidou2017association,schumacher2018association,nikpay2015comprehensive,censin2017childhood,wray2018genome}. 
We restrict to variants with a mean INFO > 0.3 in these other datasets, and also compute the median frequency per variant.
To exclude potential mismappings in the genotyped data \cite[]{kunert2020allele} that might have propagated to the imputed data, we compare median frequencies in the external data to the ones in the UK Biobank.
As we expect these potential errors to be localized around errors in the genotype data, we apply a moving-average smoothing on the frequency differences to increase power to detect these errors and also reduce false positives.
We define the threshold (of 0.03) on these smoothed differences based on visual inspection of their histogram.
This results in an initial set of 9,394,361 variants.

We then define the two sets from this large set of variants.
One is based on clumping, using a threshold $r^2 = 0.9$ over a radius of 100 Kbp and prioritizing HapMap3 variants and larger INFO scores. This results in a set ``clump'' of 2,465,478 variants, among which there are 554,655 of the initial HapMap3 variants.
For the second set, we aim at maximizing the tagging of all the initial 9,394,361 variants, i.e. $\sum_{i \in \text{all}} \max_{j \in \text{set}}{|R_{i,j}|}$, where $R_{i,j}$ is the correlation between variants $i$ and $j$ (inspired from the alternative sensitivity of \cite{agier2016systematic}). 
We design a greedy algorithm that first selects all HapMap3 variants, then adds one variant at a time, the one that maximizes the addition to this sum, until no variant can add more than 0.2.
This results in a set ``maxtag'' of 2,029,086 variants.


\subsection{GWAS sample size imputation}

In this paper, we extensively use the following formula
\begin{equation}\label{eq:approx-sd-lin}
\text{sd}(G_j) \approx \dfrac{\text{sd}(y)}{\sqrt{n_j ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~,
\end{equation}
where $\hat{\gamma}_j$ is the marginal (GWAS) effect of variant $j$, $n_j$ is the GWAS sample size associated with variant $j$, $y$ is the vector of phenotypes and ${G}_j$ is the vector of genotypes for variant $j$.
This formula is used in LDpred2 \cite{prive2020ldpred2,prive2021high}. Note that, for a binary trait for which logistic regression is used, we have instead
\begin{equation}\label{eq:approx-sd-log}
\text{sd}(G_j) \approx \dfrac{2}{\sqrt{n_j^\text{eff} ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~,
\end{equation}
where $n_j^\text{eff} = \frac{4}{1 / n_j^\text{cases} + 1 / n_j^\text{controls}}$.

We can then impute $n_j$ from equation \eqref{eq:approx-sd-lin} using
\begin{equation}\label{eq:imputeN}
n_j \approx \dfrac{\text{var}(y) / \text{var}(G_j) - \hat{\gamma}_j^2}{\text{se}(\hat{\gamma}_j)^2} ~,
\end{equation}
and impute $n_j^\text{eff}$ from equation \eqref{eq:approx-sd-log} using
\begin{equation}\label{eq:imputeNeff}
n_j^\text{eff} \approx \dfrac{4 / \text{var}(G_j) - \hat{\gamma}_j^2}{\text{se}(\hat{\gamma}_j)^2} ~.
\end{equation}
In practice, we also bound this estimate to be between $0.5 \cdot N$ and $1.1 \cdot N$, where $N$ is the global sample size.


\subsection{New implementation of lassosum in bigsnpr}

Instead of using a regularized version of the correlation matrix $R$ parameterized by $s$, $R_s = (1 - s) R + s I$ (where $0 < s \leq 1$), we use $R_{\delta} = R + \delta I$ (where $\delta > 0$), which makes it clearer that lassosum is also using L2-regularization (therefore elastic-net). 
Then, from \cite{mak2017polygenic}, the solution from lassosum can be obtained by iteratively updating 
\[
\beta_j^{(t)} =
\begin{cases}
\text{sign}\left(u_j^{(t)}\right) \left(\left|u_j^{(t)}\right| - \lambda\right) / \left(\widetilde{X}_j^T \widetilde{X}_j + \delta\right) & \text{if } \left|u_j^{(t)}\right| > \lambda ~, \\
0 & \text{otherwise.}
\end{cases}
\]
where 
\[
u_j^{(t)} = r_j - \widetilde{X}_j^T \left( \widetilde{X} \beta^{(t-1)} - \widetilde{X}_j \beta_j^{(t-1)} \right) ~.
\]
Following the notations from \cite{prive2020ldpred2} and denoting $\widetilde{X} = \frac{1}{\sqrt{n-1}} C_n G S^{-1}$, where $G$ is the genotype matrix, $C_n$ is the centering matrix and $S$ is the diagonal matrix of standard deviations of the columns of $G$.
Then $\widetilde{X}_j^T \widetilde{X} = R_{j,.} = R_{.,j}^T$ and $\widetilde{X}_j^T \widetilde{X}_j = 1$. Moreover, using the notations from \cite{prive2020ldpred2}, $u_j^{(t)} = \widehat{\beta}_j - R_{.,j}^T \beta^{(t-1)} + \beta_j^{(t-1)}$,
where $r_j = \widehat{\beta}_j =  \dfrac{\widehat{\gamma}_j}{\sqrt{n_j ~ \text{se}(\widehat{\gamma}_j)^2 + \widehat{\gamma}_j^2}}$ and $\widehat{\gamma}_j$ is the GWAS effect of variant $j$ and $n$ is the GWAS sample size \cite[]{mak2017polygenic,prive2021high}.
Then the most time-consuming part is computing $R_{.,j}^T \beta^{(t-1)}$.
To make this faster, instead of computing $R_{.,j}^T \beta^{(t-1)}$ at each iteration ($j$ and $t$), we can start with an initial vector of 0s only (for all $j$) since $\beta^{(0)} \equiv 0$, and then updating this vector when $\beta_j^{(t)} \neq \beta_j^{(t-1)}$ only. Note that only positions $k$ for which $R_{k,j} \neq 0$ must be updated in this vector $R_{.,j}^T \beta^{(t-1)}$. 

In this new implementation of the lassosum model, the input parameters are the correlation matrix $R$, the GWAS summary statistics ($\widehat{\gamma}_j$, $\text{se}(\widehat{\gamma}_j)$ and $n_j$), and the two hyper-parameters $\lambda$ and $\delta$. 
Therefore, except for the hyper-parameters, this is the exact same input as for LDpred2 \cite[]{prive2020ldpred2}.
We try $\delta \in \{0.001, 0.005, 0.02, 0.1, 0.6, 3\}$ by default in lassosum2, instead of $s \in \{0.2, 0.5, 0.8, 1.0\}$ in lassosum.
For $\lambda$, the default in lassosum uses a sequence of 20 values equally spaced on a log scale between 0.1 and 0.001. We use instead a sequence between $\lambda_0$ and $\lambda_0 / 100$ by default in lassosum2, where $\lambda_0 = \max_j \left|\widehat{\beta}_j\right|$ is the minimum $\lambda$ for which no variable enters the model because the L1-regularization is too strong.
Note that we do not provide an ``auto'' version using pseudo-validation (as in \cite{mak2017polygenic}) as we have not found it to be very robust (Figure \ref{fig:pseudoval}).
Also note that, as in LDpred2, we run lassosum2 genome-wide using a sparse correlation matrix which assumes that variants further away than 3 cM are not correlated, and therefore we do not require splitting the genome into independent LD blocks anymore (as done in lassosum).

\subsection{New LD reference}

We make three changes to the LD reference. 
First, when using imputed data, we multiply the correlation between variants $j$ and $k$ by $\sqrt{\text{INFO}_j \cdot \text{INFO}_k}$ (for $j \neq k$) since it approximates well the correlation from non-imputed data (Figure \ref{fig:compare-cor}).
Second, we also define nearly independent LD blocks using the optimal algorithm developed in \cite{prive2021optimal}.
For different numbers of blocks and maximum number of variants in each block, we use the split with the minimum cost within the ones reducing the original number of non-zero values to less than 60\% (70\% for chromosome 6).
Having a correlation matrix with independent blocks prevents the small errors in the algorithm (e.g.\ the Gibbs sampler in LDpred2) from propagating to too many variants.
It also makes running LDpred2 (and lassosum2) faster, taking about 60\% of the initial time (since only 60\% of the initial non-zero values of the correlation matrix are kept).
Finally, we have developed a new ``compact'' format for the SFBMs (sparse matrices on disk). Instead of using something similar to the standard ``compressed sparse column'' format which stores all $\{i,~x(i, j)\}$ for a given column $j$, we only store the first index $i_0$ and all the contiguous values $\{x(i_0, j),~x(i_0 + 1, j),~\dots\}$ up to the last non-zero value for this column $j$. This makes this format about twice as efficient for both LDpred2 and lassosum2.

\subsection{LDpred2-low-h2 and LDpred2-auto-rob}

Here we introduce the small changes made to LDpred2 (-grid and -auto) in order to make them more robust.
First, LDpred2-low-h2 simply consists in running LDpred2-grid by testing $h^2$ within $\{0.3, 0.7, 1, 1.4\} \cdot h^2_\text{LDSC}$ (note the added $0.3$ compared to \cite{prive2020ldpred2}), where $h^2_\text{LDSC}$ is the heritability estimate from LD score regression. Indeed, we show in simulations here that using lower values for $h^2$ may provide higher predictive performance in the case of misspecifications (thanks to more shrinkage of the effects).
In simulations, because of the large misspecifications, we use a larger grid over $\{0.01, 0.1, 0.3, 0.7, 1, 1.4\} \cdot h^2_\text{LDSC}$.

For LDpred2-auto, we introduce two new parameters. The first one, \texttt{shrink\_corr}, allows for shrinking off-diagonal elements of the correlation matrix. This is similar to parameter `s' in lassosum, and act as a regularization. We use a value of 0.9 in simulations and 0.95 in real data when running ``LDpred2-auto-rob'' (and the default value of 1, without any effect, when running ``LDpred2-auto'').
The second new parameter, \texttt{allow\_jump\_sign}, controls whether variants can change sign over two consecutive iterations of the Gibbs sampler. When setting this parameter to false (in the method we name ``LDpred2-auto-rob'' here), this forces the effects to go through 0 before changing sign. This is useful to prevent instability (oscillation and ultimately divergence) of the Gibbs sampler under large misspecifications, and is also useful for accelerating convergence of chains with a large initial value for $p$, the proportion of causal variants.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
%\vspace*{5em}

\section*{Code availability}

All code used for this paper is available at \url{https://github.com/privefl/paper-misspec/tree/master/code}.
The latest version of R package bigsnpr can be installed from GitHub.
Two tutorials on running LDpred2 and lassosum2 using R package bigsnpr are available at \url{https://privefl.github.io/bigsnpr/articles/LDpred2.html} and \url{https://privefl.github.io/bigsnpr-extdoc/polygenic-scores-pgs.html}.
We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.

\section*{Acknowledgements}

Authors thank Timothy Shin Heng Mak, Shing Wan Choi, and Matthew Stephens for helpful discussions. 
Authors also thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024.

\section*{Funding}

F.P.\ and B.J.V.\ are supported by the Danish National Research Foundation (Niels Bohr Professorship to Prof. John McGrath).
B.J.V.\ is also supported by a Lundbeck Foundation Fellowship (R335-2019-2339).

\section*{Declaration of Interests}

The authors declare no competing interests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\vspace*{3em}

\bibliographystyle{natbib}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
